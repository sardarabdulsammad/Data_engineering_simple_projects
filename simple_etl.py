# -*- coding: utf-8 -*-
"""Simple_ETL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dnTHGWJ_LH-zoxCaGsafGCHZccLsQ6Xz

**Definition:**
*it is the process of extracting large amounts of data from multiple sources and formats and transforming it into one specific format before loading it into a database or target file.*
"""

import pandas as pd
import glob
#in glob function input will be file extension and output will be list of all files
# list_csv=glob.glob('*.csv')
# list_json=glob.glob('*.json')


#output will be all the file paths containing cvs an jsons respectively

def extract_from_csv(file):
  DataFrame=pd.read_csv(file)
  return DataFrame
  #same for json format

def extract_from_json(file):
  DataFrame=pd.read_json(file)
  return DataFrame

def extract():
  #create an empty datafrom to hold large amount of data

  Extracted_Data = pd.DataFrame(colums=["name", "height", "weight"])
  #process all csv files
  for csv_file in glob.glob('.*csv'):
    Extracted_Data=Extracted_Data.append(extract_from_csv(csv_file), ignore_index=True) #ignore_index meaning new added data in table will be numbered in formal formate.
  #process all json files
  for jsonfile in glob.glob('*.json'):
    Extracted_Data=Extracted_Data.append(extract_from_json(jsonfile),ignore_index=True)
  return Extracted_Data

#Transform

def transform(data):
  data['height']=round(data.height*0.24,2) #round it to two decimal places
  data['weight'] = round(data.weight*0.24,2) #round it to two decimal places
  return(data)

#load

def load(target_file,data_to_load):
  data_to_load.to_csv(target_file)

target_file="transformeddata.csv"


#logging

extracted_Data=extract();
Transformed_data=transform(extracted_Data)
load(target_file,Transformed_data)